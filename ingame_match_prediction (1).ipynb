{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6409d235",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a522d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# 1. Preprocess Matches Data\n",
    "# ===========================\n",
    "matches = pd.read_csv('matches.csv')\n",
    "\n",
    "# Drop unnecessary columns and rename team columns (we won't use home/away directly)\n",
    "cols_to_drop = ['match_type', 'player_of_match', 'target_runs', 'target_overs', \n",
    "                'super_over', 'umpire1', 'umpire2', 'season', 'city', 'date', \n",
    "                'toss_winner', 'toss_decision', 'result_margin', 'result', 'method',\n",
    "                'team1', 'team2']\n",
    "matches = matches.drop(columns=cols_to_drop)\n",
    "\n",
    "# We need winner and venue to compute our target and derive venue-based info.\n",
    "# Standardize team names in 'winner'\n",
    "team_mapping = {\n",
    "    \"Royal Challengers Bengaluru\": \"Royal Challengers Bangalore\",\n",
    "    \"Rising Pune Supergiant\": \"Rising Pune Supergiants\",\n",
    "    \"Delhi Daredevils\": \"Delhi Capitals\",\n",
    "    \"Kings XI Punjab\": \"Punjab Kings\"\n",
    "}\n",
    "matches['winner'] = matches['winner'].replace(team_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d6305fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map venues to canonical names (customize mapping as needed)\n",
    "venue_mapping = {\n",
    "    \"M Chinnaswamy Stadium\": \"M Chinnaswamy Stadium\",\n",
    "    \"M.Chinnaswamy Stadium\": \"M Chinnaswamy Stadium\",\n",
    "    \"M Chinnaswamy Stadium, Bengaluru\": \"M Chinnaswamy Stadium\",\n",
    "    \n",
    "    \"Punjab Cricket Association Stadium, Mohali\": \"Punjab Cricket Association Stadium, Mohali\",\n",
    "    \"Punjab Cricket Association IS Bindra Stadium, Mohali\": \"Punjab Cricket Association Stadium, Mohali\",\n",
    "    \"Punjab Cricket Association IS Bindra Stadium\": \"Punjab Cricket Association Stadium, Mohali\",\n",
    "    \"Punjab Cricket Association IS Bindra Stadium, Mohali, Chandigarh\": \"Punjab Cricket Association Stadium, Mohali\",\n",
    "    \n",
    "    \"Wankhede Stadium\": \"Wankhede Stadium\",\n",
    "    \"Wankhede Stadium, Mumbai\": \"Wankhede Stadium\",\n",
    "    \n",
    "    \"Eden Gardens\": \"Eden Gardens\",\n",
    "    \"Eden Gardens, Kolkata\": \"Eden Gardens\",\n",
    "    \n",
    "    \"Sawai Mansingh Stadium\": \"Sawai Mansingh Stadium\",\n",
    "    \"Sawai Mansingh Stadium, Jaipur\": \"Sawai Mansingh Stadium\",\n",
    "    \n",
    "    \"Rajiv Gandhi International Stadium, Uppal\": \"Rajiv Gandhi International Stadium, Hyderabad\",\n",
    "    \"Rajiv Gandhi International Stadium, Uppal, Hyderabad\": \"Rajiv Gandhi International Stadium, Hyderabad\",\n",
    "    \"Rajiv Gandhi International Stadium\": \"Rajiv Gandhi International Stadium, Hyderabad\",\n",
    "    \n",
    "    \"MA Chidambaram Stadium, Chepauk\": \"MA Chidambaram Stadium, Chepauk\",\n",
    "    \"MA Chidambaram Stadium, Chepauk, Chennai\": \"MA Chidambaram Stadium, Chepauk\",\n",
    "    \"MA Chidambaram Stadium\": \"MA Chidambaram Stadium, Chepauk\",\n",
    "    \n",
    "    \"Dr DY Patil Sports Academy\": \"Dr DY Patil Sports Academy\",\n",
    "    \"Dr DY Patil Sports Academy, Mumbai\": \"Dr DY Patil Sports Academy\",\n",
    "    \n",
    "    \"Brabourne Stadium\": \"Brabourne Stadium\",\n",
    "    \"Brabourne Stadium, Mumbai\": \"Brabourne Stadium\",\n",
    "    \n",
    "    \"Himachal Pradesh Cricket Association Stadium\": \"Himachal Pradesh Cricket Association Stadium\",\n",
    "    \"Himachal Pradesh Cricket Association Stadium, Dharamsala\": \"Himachal Pradesh Cricket Association Stadium\",\n",
    "    \n",
    "    \"Dr. Y.S. Rajasekhara Reddy ACA-VDCA Cricket Stadium\": \"Dr. Y.S. Rajasekhara Reddy ACA-VDCA Cricket Stadium\",\n",
    "    \"Dr. Y.S. Rajasekhara Reddy ACA-VDCA Cricket Stadium, Visakhapatnam\": \"Dr. Y.S. Rajasekhara Reddy ACA-VDCA Cricket Stadium\",\n",
    "    \n",
    "    \"Subrata Roy Sahara Stadium\": \"Subrata Roy Sahara Stadium\",\n",
    "    \n",
    "    \"Maharashtra Cricket Association Stadium\": \"Maharashtra Cricket Association Stadium\",\n",
    "    \"Maharashtra Cricket Association Stadium, Pune\": \"Maharashtra Cricket Association Stadium\",\n",
    "    \n",
    "    \n",
    "    \"Arun Jaitley Stadium\": \"Arun Jaitley Stadium, Delhi\",\n",
    "    \"Arun Jaitley Stadium, Delhi\": \"Arun Jaitley Stadium, Delhi\",\n",
    "    \"Feroz Shah Kotla\":\"Arun Jaitley Stadium, Delhi\",\n",
    "    \n",
    "}\n",
    "matches['venue_canonical'] = matches['venue'].map(venue_mapping).fillna(matches['venue'])\n",
    "matches = matches[['match_id', 'winner', 'venue_canonical']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ace7a863",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# 2. Preprocess Deliveries Data\n",
    "# ===============================\n",
    "deliveries = pd.read_csv('deliveries.csv')\n",
    "cols_deliveries = ['match_id', 'inning', 'batting_team', 'bowling_team', \n",
    "                   'over', 'ball', 'total_runs', 'is_wicket']\n",
    "deliveries_subset = deliveries[cols_deliveries].copy()\n",
    "\n",
    "# Standardize team names in deliveries data\n",
    "for col in ['batting_team', 'bowling_team']:\n",
    "    deliveries_subset[col] = deliveries_subset[col].replace(team_mapping)\n",
    "\n",
    "# Compute aggregated features from ball-by-ball data\n",
    "deliveries_subset['cum_runs'] = deliveries_subset.groupby(['match_id', 'inning'])['total_runs'].cumsum()\n",
    "deliveries_subset['cum_wickets'] = deliveries_subset.groupby(['match_id', 'inning'])['is_wicket'].cumsum()\n",
    "deliveries_subset['overs_completed'] = deliveries_subset['over'] + (deliveries_subset['ball'] - 1) / 6\n",
    "deliveries_subset['current_run_rate'] = np.where(\n",
    "    deliveries_subset['overs_completed'] == 0,\n",
    "    0,\n",
    "    deliveries_subset['cum_runs'] / deliveries_subset['overs_completed']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9623037a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================\n",
    "# 3. Compute Target & Required Run Rate (2nd Innings)\n",
    "# ==============================================\n",
    "# Compute first innings final score and target = score + 1\n",
    "first_innings = deliveries_subset[deliveries_subset['inning'] == 1]\n",
    "first_innings_final = first_innings.groupby('match_id')['cum_runs'].max().reset_index()\n",
    "first_innings_final = first_innings_final.rename(columns={'cum_runs': 'first_innings_score'})\n",
    "first_innings_final['target'] = first_innings_final['first_innings_score'] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "352e8020",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# 4. Merge Data & Compute RRR\n",
    "# ================================\n",
    "# Merge deliveries with matches and target info\n",
    "final_data = pd.merge(deliveries_subset, matches, on='match_id', how='left')\n",
    "final_data = pd.merge(final_data, first_innings_final[['match_id', 'target']], on='match_id', how='left')\n",
    "\n",
    "# Compute remaining overs (T20 match: 20 overs total)\n",
    "remaining_overs = 20 - final_data['overs_completed']\n",
    "final_data['required_run_rate'] = np.where(\n",
    "    (final_data['inning'] == 2) & (remaining_overs > 0),\n",
    "    (final_data['target'] - final_data['cum_runs']) / remaining_overs,\n",
    "    0\n",
    ")\n",
    "final_data['required_run_rate'] = final_data['required_run_rate'].replace([np.inf, -np.inf], 0)\n",
    "\n",
    "# Create target variable: win = 1 if batting_team equals winner, else 0.\n",
    "final_data['win'] = (final_data['batting_team'] == final_data['winner']).astype(int)\n",
    "\n",
    "# Filter to second innings only (since required run rate applies to 2nd innings)\n",
    "final_data = final_data[final_data['inning'] == 2].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91b93693",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================\n",
    "# 5. Select Features for Live Prediction\n",
    "# ====================================\n",
    "# We need:\n",
    "#   - Numeric: inning, cum_runs, cum_wickets, current_run_rate, required_run_rate, target\n",
    "#   - Categorical (encoded): batting_team, bowling_team, venue_canonical\n",
    "keep_cols = ['match_id', 'inning', 'cum_runs', 'cum_wickets', 'current_run_rate', \n",
    "             'required_run_rate', 'target', 'batting_team', 'bowling_team', 'venue_canonical', 'win']\n",
    "final_data = final_data[keep_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f99edf48",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 125741 entries, 124 to 260919\n",
      "Data columns (total 11 columns):\n",
      " #   Column             Non-Null Count   Dtype  \n",
      "---  ------             --------------   -----  \n",
      " 0   match_id           125741 non-null  int64  \n",
      " 1   inning             125741 non-null  int64  \n",
      " 2   cum_runs           125741 non-null  int64  \n",
      " 3   cum_wickets        125741 non-null  int64  \n",
      " 4   current_run_rate   125741 non-null  float64\n",
      " 5   required_run_rate  125741 non-null  float64\n",
      " 6   target             125741 non-null  int64  \n",
      " 7   batting_team       125741 non-null  object \n",
      " 8   bowling_team       125741 non-null  object \n",
      " 9   venue_canonical    125741 non-null  object \n",
      " 10  win                125741 non-null  int64  \n",
      "dtypes: float64(2), int64(6), object(3)\n",
      "memory usage: 11.5+ MB\n"
     ]
    }
   ],
   "source": [
    "final_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8faa0203",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================\n",
    "# 6. Encode Categorical Variables\n",
    "# ====================================\n",
    "# For team names\n",
    "le_team = LabelEncoder()\n",
    "final_data['batting_team_encoded'] = le_team.fit_transform(final_data['batting_team'])\n",
    "final_data['bowling_team_encoded'] = le_team.transform(final_data['bowling_team'])\n",
    "\n",
    "# Save the team encoder\n",
    "joblib.dump(le_team, 'le_team.pkl')\n",
    "\n",
    "# For venue\n",
    "le_venue = LabelEncoder()\n",
    "final_data['venue_canonical_encoded'] = le_venue.fit_transform(final_data['venue_canonical'])\n",
    "\n",
    "# Save the venue encoder\n",
    "joblib.dump(le_venue, 'le_venue.pkl')\n",
    "\n",
    "# Drop original categorical columns\n",
    "final_data = final_data.drop(columns=['batting_team', 'bowling_team', 'venue_canonical'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e5969210",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================\n",
    "# 7. Final Feature Set and Train/Test Split\n",
    "# ====================================\n",
    "# Final features for training:\n",
    "# inning, cum_runs, cum_wickets, current_run_rate, required_run_rate, target,\n",
    "# batting_team_encoded, bowling_team_encoded, venue_canonical_encoded\n",
    "# Target: win\n",
    "final_features = ['inning', 'cum_runs', 'cum_wickets', 'current_run_rate', \n",
    "                  'required_run_rate', 'target', \n",
    "                  'batting_team_encoded', 'bowling_team_encoded', 'venue_canonical_encoded', 'win']\n",
    "\n",
    "final_data = final_data[final_features]\n",
    "\n",
    "# Perform a match-level split to avoid leakage\n",
    "unique_matches = final_data['match_id'].unique() if 'match_id' in final_data.columns else np.unique(final_data.index) \n",
    "# NOTE: Since we dropped match_id, we assume index represents different match snapshots; ideally, you'd preserve match_id\n",
    "# Here, we assume final_data still has match_id; if not, re-merge it for splitting.\n",
    "if 'match_id' in final_data.columns:\n",
    "    split_ids = final_data['match_id'].unique()\n",
    "    train_ids, test_ids = train_test_split(split_ids, test_size=0.2, random_state=42)\n",
    "    train_data = final_data[final_data['match_id'].isin(train_ids)].copy()\n",
    "    test_data = final_data[final_data['match_id'].isin(test_ids)].copy()\n",
    "    train_data = train_data.drop(columns=['match_id'])\n",
    "    test_data = test_data.drop(columns=['match_id'])\n",
    "else:\n",
    "    # If match_id was dropped, use random split (less ideal)\n",
    "    train_data, test_data = train_test_split(final_data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Separate features and target\n",
    "target_col = 'win'\n",
    "X_train = train_data.drop(columns=[target_col])\n",
    "y_train = train_data[target_col]\n",
    "X_test = test_data.drop(columns=[target_col])\n",
    "y_test = test_data[target_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2afcf7a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: Logistic Regression\n",
      "Training Accuracy: 78.14%\n",
      "Testing Accuracy: 77.78%\n",
      "Classification Report (Test):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.75      0.76     12033\n",
      "           1       0.78      0.81      0.79     13116\n",
      "\n",
      "    accuracy                           0.78     25149\n",
      "   macro avg       0.78      0.78      0.78     25149\n",
      "weighted avg       0.78      0.78      0.78     25149\n",
      "\n",
      "Confusion Matrix (Test):\n",
      "[[ 8985  3048]\n",
      " [ 2539 10577]]\n",
      "------------------------------------------------------------\n",
      "\n",
      "Model: Random Forest\n",
      "Training Accuracy: 99.99%\n",
      "Testing Accuracy: 99.66%\n",
      "Classification Report (Test):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     12033\n",
      "           1       1.00      1.00      1.00     13116\n",
      "\n",
      "    accuracy                           1.00     25149\n",
      "   macro avg       1.00      1.00      1.00     25149\n",
      "weighted avg       1.00      1.00      1.00     25149\n",
      "\n",
      "Confusion Matrix (Test):\n",
      "[[11986    47]\n",
      " [   38 13078]]\n",
      "------------------------------------------------------------\n",
      "\n",
      "Model: XGBoost\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Users\\aabid\\envs\\ML\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [15:04:20] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 99.73%\n",
      "Testing Accuracy: 99.53%\n",
      "Classification Report (Test):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00     12033\n",
      "           1       0.99      1.00      1.00     13116\n",
      "\n",
      "    accuracy                           1.00     25149\n",
      "   macro avg       1.00      1.00      1.00     25149\n",
      "weighted avg       1.00      1.00      1.00     25149\n",
      "\n",
      "Confusion Matrix (Test):\n",
      "[[11952    81]\n",
      " [   36 13080]]\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# ====================================\n",
    "# 8. Train Multiple Models and Evaluate\n",
    "# ====================================\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=42),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    \"XGBoost\": XGBClassifier(objective='binary:logistic', eval_metric='logloss',\n",
    "                             use_label_encoder=False, random_state=42)\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nModel: {name}\")\n",
    "    model.fit(X_train, y_train)\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    \n",
    "    train_acc = accuracy_score(y_train, y_train_pred)\n",
    "    test_acc = accuracy_score(y_test, y_test_pred)\n",
    "    \n",
    "    print(\"Training Accuracy: {:.2f}%\".format(train_acc * 100))\n",
    "    print(\"Testing Accuracy: {:.2f}%\".format(test_acc * 100))\n",
    "    print(\"Classification Report (Test):\")\n",
    "    print(classification_report(y_test, y_test_pred))\n",
    "    print(\"Confusion Matrix (Test):\")\n",
    "    print(confusion_matrix(y_test, y_test_pred))\n",
    "    print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "93313016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for Logistic Regression: {'C': 0.1}\n",
      "Best CV score for Logistic Regression: 0.7813\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import numpy as np\n",
    "\n",
    "# ---------------------------\n",
    "# Hyperparameter Tuning for Logistic Regression\n",
    "# ---------------------------\n",
    "lr = LogisticRegression(max_iter=1000, random_state=42)\n",
    "param_dist_lr = {\n",
    "    'C': [0.01, 0.1, 1, 10, 100]\n",
    "}\n",
    "\n",
    "rand_search_lr = RandomizedSearchCV(\n",
    "    lr,\n",
    "    param_distributions=param_dist_lr,\n",
    "    n_iter=5,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "rand_search_lr.fit(X_train, y_train)\n",
    "print(\"Best parameters for Logistic Regression:\", rand_search_lr.best_params_)\n",
    "print(\"Best CV score for Logistic Regression: {:.4f}\".format(rand_search_lr.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3e6cb0b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best parameters for Random Forest: {'n_estimators': 50, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': None}\n",
      "Best CV score for Random Forest: 0.9957\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------\n",
    "# Hyperparameter Tuning for Random Forest\n",
    "# ---------------------------\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "param_dist_rf = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 5, 10],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "rand_search_rf = RandomizedSearchCV(\n",
    "    rf,\n",
    "    param_distributions=param_dist_rf,\n",
    "    n_iter=10,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "rand_search_rf.fit(X_train, y_train)\n",
    "print(\"\\nBest parameters for Random Forest:\", rand_search_rf.best_params_)\n",
    "print(\"Best CV score for Random Forest: {:.4f}\".format(rand_search_rf.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dff23ba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Users\\aabid\\envs\\ML\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [15:06:51] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best parameters for XGBoost: {'reg_lambda': 1, 'reg_alpha': 0, 'n_estimators': 100, 'min_child_weight': 5, 'max_depth': 7, 'learning_rate': 0.2, 'gamma': 0.5}\n",
      "Best CV score for XGBoost: 0.9945\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------\n",
    "# Hyperparameter Tuning for XGBoost\n",
    "# ---------------------------\n",
    "xgb = XGBClassifier(objective='binary:logistic', eval_metric='logloss', \n",
    "                    use_label_encoder=False, random_state=42)\n",
    "param_dist_xgb = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'min_child_weight': [1, 3, 5],\n",
    "    'gamma': [0, 0.1, 0.5],\n",
    "    'reg_alpha': [0, 0.1, 0.5],\n",
    "    'reg_lambda': [1, 1.5, 2]\n",
    "}\n",
    "\n",
    "rand_search_xgb = RandomizedSearchCV(\n",
    "    xgb,\n",
    "    param_distributions=param_dist_xgb,\n",
    "    n_iter=10,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "rand_search_xgb.fit(X_train, y_train)\n",
    "print(\"\\nBest parameters for XGBoost:\", rand_search_xgb.best_params_)\n",
    "print(\"Best CV score for XGBoost: {:.4f}\".format(rand_search_xgb.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ae5fe6e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Model Testing Accuracy: 99.66%\n",
      "Final Model Classification Report (Test):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     12033\n",
      "           1       1.00      1.00      1.00     13116\n",
      "\n",
      "    accuracy                           1.00     25149\n",
      "   macro avg       1.00      1.00      1.00     25149\n",
      "weighted avg       1.00      1.00      1.00     25149\n",
      "\n",
      "Final Model Confusion Matrix (Test):\n",
      "[[11986    47]\n",
      " [   38 13078]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['final_rf_model.pkl']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assume rand_search_rf.best_estimator_ is our final tuned Random Forest model\n",
    "final_rf_model = rand_search_rf.best_estimator_\n",
    "final_rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate on test data\n",
    "y_test_pred = final_rf_model.predict(X_test)\n",
    "print(\"Final Model Testing Accuracy: {:.2f}%\".format(accuracy_score(y_test, y_test_pred)*100))\n",
    "print(\"Final Model Classification Report (Test):\")\n",
    "print(classification_report(y_test, y_test_pred))\n",
    "print(\"Final Model Confusion Matrix (Test):\")\n",
    "print(confusion_matrix(y_test, y_test_pred))\n",
    "\n",
    "# Save the final model\n",
    "joblib.dump(final_rf_model, 'final_rf_model.pkl')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
